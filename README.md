# Travaux Pratiques en Reinforcement Learning

## ğŸ“Œ PrÃ©sentation
Ce dÃ©pÃ´t propose une sÃ©rie de quatre Travaux Pratiques (TP) en **Reinforcement Learning (RL)**, explorant diffÃ©rentes approches et algorithmes appliquÃ©s Ã  des environnements variÃ©s.

Chaque TP est conÃ§u pour offrir une comprÃ©hension progressive des concepts clÃ©s du RL, en passant de l'exploration d'environnements simples Ã  des techniques avancÃ©es comme **Policy Gradient**.

---

## ğŸ“‚ Contenu des TPs

### ğŸ— TP1 : DÃ©couverte de Gymnasium et CartPole
- **Fichier** : `TP1.ipynb`
- **Objectif** : Prise en main de l'environnement **CartPole-v1** via Gymnasium.
- **Concepts abordÃ©s** :
  - Initialisation de lâ€™environnement et exploration des espaces dâ€™actions et dâ€™observations.
  - ExÃ©cution d'actions alÃ©atoires et analyse des rÃ©compenses et Ã©tats.
  - Interaction manuelle pour comprendre la dynamique du systÃ¨me.

### â„ TP2 : Q-Learning sur FrozenLake
- **Fichier** : `TP2.ipynb`
- **Objectif** : ImplÃ©menter **Q-Learning** pour rÃ©soudre lâ€™environnement **FrozenLake**.
- **Concepts abordÃ©s** :
  - CrÃ©ation et initialisation d'une **Q-table**.
  - EntraÃ®nement dâ€™un agent avec Q-Learning (rÃ©glage des hyperparamÃ¨tres **alpha, gamma, epsilon**).
  - Ã‰valuation des performances avec affichage du taux de rÃ©ussite.

### ğŸš¦ TP3 : Q-Learning vs SARSA sur un Environnement de Trafic
- **Fichier** : `TP3.ipynb`
- **Objectif** : Comparer **Q-Learning** et **SARSA** sur un environnement personnalisÃ© de gestion du trafic.
- **Concepts abordÃ©s** :
  - Initialisation de **TrafficEnvironment**.
  - ImplÃ©mentation des deux algorithmes avec des paramÃ¨tres similaires.
  - Comparaison des performances via des **courbes de rÃ©compenses**.

### ğŸš– TP4 : Policy Gradient (PPO) sur Taxi-v3
- **Fichier** : `TP4.ipynb`
- **Objectif** : EntraÃ®ner un agent avec **PPO (Proximal Policy Optimization)** sur **Taxi-v3**.
- **Concepts abordÃ©s** :
  - Mise en place dâ€™une **politique** et de valeurs associÃ©es.
  - Optimisation avec PPO (incluant **reward shaping** et **clipping**).
  - Ã‰valuation des performances aprÃ¨s entraÃ®nement.

---

## ğŸ›  PrÃ©requis

- **Python 3.9+**
- BibliothÃ¨ques requises :
  ```bash
  pip install gymnasium numpy matplotlib traffic_env
  ```

---

## ğŸš€ Utilisation

ExÃ©cutez les notebooks dans l'ordre **TP1 â†’ TP4** pour une progression logique des concepts.
Chaque TP est commentÃ© pour faciliter la comprÃ©hension et l'expÃ©rimentation.

---

## âœï¸ Auteur

**BOURI Souhail**

ğŸ“Œ *N'hÃ©sitez pas Ã  contribuer ou signaler des amÃ©liorations !* ğŸš€

